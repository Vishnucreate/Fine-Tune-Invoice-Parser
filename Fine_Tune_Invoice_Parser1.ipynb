{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f43537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# üßæ Fine-Tune Invoice Parser\\n\",\n",
    "    \"This Colab notebook fine-tunes **SmolVLM / Idefics-3** on the dataset `mychen76/invoices-and-receipts_ocr_v1` using **TRL + LoRA**.\\n\",\n",
    "    \"\\n\",\n",
    "    \"It includes: data loading, preprocessing, fine-tuning, and evaluation ‚Äî all in one file.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"!pip install -U \\\"transformers>=4.43.0\\\" \\\"trl>=0.9.0\\\" \\\"peft>=0.11\\\" \\\"datasets\\\" \\\"torch\\\" \\\"bitsandbytes\\\" \\\"accelerate\\\"\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"from datasets import load_dataset\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"from transformers import Idefics3ForConditionalGeneration, AutoProcessor\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"from peft import LoraConfig, get_peft_model\\n\",\n",
    "    \"from trl import SFTTrainer, SFTConfig\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"\\n\",\n",
    "    \"os.environ['WANDB_DISABLED'] = 'true'\\n\",\n",
    "    \"\\n\",\n",
    "    \"ds = load_dataset('mychen76/invoices-and-receipts_ocr_v1')\\n\",\n",
    "    \"\\n\",\n",
    "    \"def flatten_example(example):\\n\",\n",
    "    \"    parsed = json.loads(example['parsed_data'])\\n\",\n",
    "    \"    structured = parsed.get('json', '{}')\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        structured_json = json.loads(structured.replace(\\\"'\\\", '\\\"'))\\n\",\n",
    "    \"    except:\\n\",\n",
    "    \"        structured_json = {'error': 'invalid_json'}\\n\",\n",
    "    \"    prompt = 'Extract all invoice fields and return as JSON.'\\n\",\n",
    "    \"    output = json.dumps(structured_json)\\n\",\n",
    "    \"    return {'text': f'{prompt}\\\\n{output}'}\\n\",\n",
    "    \"\\n\",\n",
    "    \"flat_train = ds['train'].map(flatten_example)\\n\",\n",
    "    \"flat_valid = ds['valid'].map(flatten_example)\\n\",\n",
    "    \"\\n\",\n",
    "    \"model = Idefics3ForConditionalGeneration.from_pretrained(\\n\",\n",
    "    \"    'HuggingFaceTB/SmolVLM-Instruct',\\n\",\n",
    "    \"    torch_dtype=torch.float16,\\n\",\n",
    "    \"    device_map='auto'\\n\",\n",
    "    \")\\n\",\n",
    "    \"processor = AutoProcessor.from_pretrained('HuggingFaceTB/SmolVLM-Instruct')\\n\",\n",
    "    \"\\n\",\n",
    "    \"lora_config = LoraConfig(r=8, lora_alpha=32, lora_dropout=0.1, target_modules=['q_proj', 'v_proj'], bias='none', task_type='CAUSAL_LM')\\n\",\n",
    "    \"model = get_peft_model(model, lora_config)\\n\",\n",
    "    \"\\n\",\n",
    "    \"sft_config = SFTConfig(per_device_train_batch_size=2, num_train_epochs=3, learning_rate=1e-4, fp16=True, output_dir='./outputs', report_to='none')\\n\",\n",
    "    \"trainer = SFTTrainer(model=model, args=sft_config, train_dataset=flat_train, eval_dataset=flat_valid, processing_class=processor)\\n\",\n",
    "    \"trainer.train()\\n\",\n",
    "    \"trainer.model.save_pretrained('./fine_tuned_model')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## üîç Evaluation\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"from transformers import Idefics3ForConditionalGeneration, AutoProcessor\\n\",\n",
    "    \"from datasets import load_dataset\\n\",\n",
    "    \"import torch, json\\n\",\n",
    "    \"\\n\",\n",
    "    \"model = Idefics3ForConditionalGeneration.from_pretrained('./fine_tuned_model', torch_dtype='auto', device_map='auto')\\n\",\n",
    "    \"processor = AutoProcessor.from_pretrained('./fine_tuned_model')\\n\",\n",
    "    \"ds = load_dataset('mychen76/invoices-and-receipts_ocr_v1')['valid']\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i, ex in enumerate(ds.select(range(5))):\\n\",\n",
    "    \"    parsed = json.loads(ex['parsed_data']).get('json', '{}')\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        target_json = json.loads(parsed.replace(\\\"'\\\", '\\\"'))\\n\",\n",
    "    \"    except:\\n\",\n",
    "    \"        target_json = {'error': 'invalid_json'}\\n\",\n",
    "    \"    prompt = 'Extract all invoice fields and return as JSON.'\\n\",\n",
    "    \"    target_text = json.dumps(target_json)\\n\",\n",
    "    \"    full = f'{prompt}\\\\n{target_text}'\\n\",\n",
    "    \"    enc = processor.tokenizer(full, return_tensors='pt', truncation=True, padding='max_length', max_length=512)\\n\",\n",
    "    \"    labels = enc['input_ids'].clone()\\n\",\n",
    "    \"    prompt_len = len(processor.tokenizer(prompt)['input_ids'])\\n\",\n",
    "    \"    labels[:, :prompt_len] = -100\\n\",\n",
    "    \"    enc = {k: v.to(model.device) for k, v in enc.items()}\\n\",\n",
    "    \"    labels = labels.to(model.device)\\n\",\n",
    "    \"    with torch.no_grad():\\n\",\n",
    "    \"        loss = model(**enc, labels=labels).loss\\n\",\n",
    "    \"    print(f'[{i}] Loss: {loss.item():.4f}')\\n\",\n",
    "    \"    out = processor.tokenizer.batch_decode(model.generate(**enc, max_new_tokens=256), skip_special_tokens=True)[0]\\n\",\n",
    "    \"    print('Prediction:', out[:300])\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.10\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
